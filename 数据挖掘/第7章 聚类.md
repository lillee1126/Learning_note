# 聚类分析的特征

1. 适用于没有先验知识的分类
2. 可以处理多个变量决定的分类
3. 主要用于探索性的研究，分析结果可以提供多个可能的解，选择最终的解需要研究者的主观判断和后续分析
4. 聚类分析的解完全依赖与研究者所选择的聚类变量，增加或删除一些变量对最终的解都可能产生实质性的影响
5. 异常值和特殊的变量对聚类有较大的影响，当分类变量的测量尺度不一致时需要实现进行标准化处理

# 聚类分析的基本步骤

1. 数据预处理
2. 相似性度量
3. 聚类分析方法
4. 评估聚类结果

# 基于划分的聚类方法

划分方法是**基于距离**判断样本的相似度，通过不断迭代将含有多个样本的数据集划分成若干簇，使每个样本都属于且只属于一个簇

### k-means

该算法需事先给定聚类数以及初始簇中心，通过迭代的方式使样本与各自所属类别的簇中心的距离平方和最小，属于启发式的贪心算法，得到的经常是局部最优解

| 优点                   | 缺点                                 |
| ---------------------- | ------------------------------------ |
| 简单高效，时间复杂度低 | 需预先指定簇数 *k*                   |
| 球状簇聚类效果好       | 对初始质心敏感，易陷入局部最优       |
| 可解释性强             | 对异常值和噪声敏感                   |
| 易于优化和扩展         | 无法识别非球状、不规则形状的簇       |
| -                      | 对数据尺度和分布敏感，高维数据效果差 |

### k-medoids

该算法选用簇中数据样本的中心样本来代替簇中心，这种改进在一定程度上能够减少噪声对模型造成的影响

| 优点                             | 缺点                             |
| -------------------------------- | -------------------------------- |
| 对异常值和噪声不敏感             | 计算复杂度高，效率低于 K-Means   |
| 支持非数值型数据（基于距离度量） | 需预先指定簇数 *k*               |
| 中心点是真实样本，可解释性强     | 对初始中心点敏感，易陷入局部最优 |
| 算法逻辑与 K-Means 一致，易理解  | 仅适合中小规模数据集             |
| -                                | 无法识别非球状、不规则形状的簇   |

### k-means与k-medoids的区别

- 当存在噪声和孤立样本数据时，k-medoids别k-means更健壮，没有k-means那样容易受到极端数据的影响
- 在时间复杂度上，k-means算法的时间复杂度为**O（nkt）**，而k-medoids算法的时间复杂度大约为**O($n^2$)**,后者执行代价要高得多

基于划分的聚类方法的缺点是它需要预先设定类别数目k，并且初始中心的选择和噪声会对聚类结果产生很大的影响

# 基于层次的聚类方法

### AGNES

### DIANA

# 基于密度的聚类方法

与其他聚类方法的根本不同是：它不是基于聚类的，而是基于密度的。由于这个特点，基于密度的方法可以克服基于距离的算法只能发现“类圆形”聚类的缺点。

主要思想：只要在给定半径内邻近区域的密度超过某个阈值，就把它添加到与之相近的簇类中

密度聚类的簇是最大密度相连样本的集合，不包含在任何簇中的数据样本被称为“噪声”

### DBSCAN

DBSCAN不进行任何的预处理，当数据量非常大时必须有大内存支持，I/O消耗也非常大

如果采用空间索引，DBSCAN的计算复杂度是O(nlogn)，n为样本总数，否则复杂度为O($n^2$)，聚类过程的大部分时间用在了区域查询操作上

算法描述：寻找核心样本，根据核心样本创建新簇，反复寻找从这些核心样本密度可达的数据样本，当没有新的数据样本可以被添加到任何簇时，该过程结束

| 优点                           | 缺点                             |
| ------------------------------ | -------------------------------- |
| 无需指定簇数 *k*               | 对参数 *ε* 和 MinPts 高度敏感    |
| 能识别任意形状的簇             | 处理密度不均匀的数据效果差       |
| 天然识别噪声点，对异常值不敏感 | 高维数据聚类精度低（维度灾难）   |
| 结果稳定，无初始化敏感问题     | 计算复杂度高，超大规模数据效率低 |
| -                              | 对数据尺度敏感，需预先标准化     |

### OPTICS

### DENCLUE

# 基于网格的聚类方法

### CLIQUE

### STING

# 基于模型的聚类方法

### EM

### COBWEB

# 聚类评估

### 估计聚类趋势

霍普金斯统计

### 确认簇数

- 经验方法
- 肘部方法
- 交叉验证法

### 测定聚类质量

1. 外在方法
   - 当有基准可用时，可以将基准与聚类进行比较，以评估聚类
2. 内在方法
   - 当没用基准可以时，通过考察聚类的分类情况及其紧凑情况来评估聚类
     - 轮廓系数：-1和1之间
     - $a(D^‘)$值越小，簇越紧凑
     - $D^‘$与其他簇分离的程度会随着$b(D’)$的增大而增大