# 1.传输层的功能

传输层的核心功能是**在源主机和目的主机的应用程序之间提供端到端的通信服务**，具体包括：

1. 分段与重组：将上层应用数据分割为适合网络传输的分段，到达目的端后再重组为完整数据。
2. 可靠传输：通过序号、确认、重传等机制（如 TCP 协议）保证数据无差错、不丢失、不重复、按序交付。
3. 流量控制：调节发送方速率，避免接收方缓冲区溢出。
4. 拥塞控制：感知网络拥塞并降低发送速率，缓解网络压力。
5. 多路复用与多路分解：通过端口号区分同一主机上的不同应用进程，实现多个应用共享网络连接。

### 复用和分用

应用层所有的应用进程都可以通过运输层再传送到IP层，这就是复用

运输层从IP层收到发送给各应用进程的数据后，必须分别交付指明的各应用进程，这就是分用

### 常用的熟知端口号

| 应用进程                  | 端口号 |
| ------------------------- | ------ |
| FTP(文件传输协议)         | 21     |
| TELNET(远程终端协议)      | 23     |
| SMTP(简单邮件传输协议)    | 25     |
| HTTP(超文本传输协议)      | 80     |
| HTTPS(超文本传输安全协议) | 443    |

# 2.UDP的特点、TCP的特点

### UDP：用户数据报协议

简答方便，但不可靠

- 是无连接的

  - 减小了开销和发送数据之间的时延

- 使用尽最大努力交付：

  * 不保证可靠交付，因此主机不需要维持复杂的连接状态表

- 面向报文

  - 发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付IP层

  - 接收方的UDP对IP层交上来的UDP用户数据报，去掉首部后就原封不动地交付上层的应用程序

- 没有拥塞控制

  - 因此网络出现的拥塞不会使源主机的发送速率降低，对某些实时应用是很重要的。

- 支持一对一、一对多、多对一和多对多的交互通信

- 首部开销小

  - 只有8个字节，比TCP的20个字节首部要短

首部格式：

1. 源端口：源端口号。在需要对方回信时选用，不需要时可用全0
2. 目的端口：目的端口号。在终点交付报文时必须使用
3. 长度：UDP用户数据报的长度，最小值为8（仅有首部）
4. 检验和：检验UDP用户数据报在传输中是否有错。有错就丢弃（通过12个字节的伪首部计算）

### TCP：传输控制协议

- 面向连接的运输层协议

  - 应用程序在使用TCP协议之前，必须先建立TCP连接，结束后要释放连接

- 每条TCP连接只能是点对点的

- 提供可靠交付的服务

  * 通过TCP连接传送的数据，无差错、不丢失、不重复，并且按序到达

- 提供全双工通信

  - 允许通信双方的应用进程在任何时候都能发送数据，TCP连接的两端都设有发送缓存和接受缓存

- 面向字节流

  - 虽然应用程序和TCP的交互是一次一个数据块，但TCP把应用程序交下来的数据仅仅看作是一连串无结构的字节流。

  - TCP不保证接收方应用程序所收到的数据块与发送方应用程序所发出的数据块具有对应大小的关系（例如发送方可能发送10个数据块，但接收方的TCP可能只用4个数据块就交付给上层应用程序），但是接受的字节流和发出的字节流完全一样。



TCP连接的端点叫作套接字（socket）或插口：IP地址+端口号

### 可靠传输的工作特点

#### 停止等待协议

 - 无差错情况

   - A发送完分组M1后暂停发送，等待B的确认。B收到M1就向A发送确认，然后A再发送下一个分组M2
   
 - 出现差错

   **超时重传**：B接受M1时检测出了差错，然后丢弃，B不通知A，A只要超过一段时间仍然没有收到确定，就认为刚才发送的分组丢失了，重传前面发送过的分组，所以需要设置**重传计时器**

   需要注意三点：

   1. A发送完一个分组后，**必须暂时保留已发送的分组的副本**

   2. 分组和确认分组都要进行**编号**

   3. 超时计时器设置的重传时间**应当比数据在分组传输的平均往返时间更长一些

- 确认丢失和确认迟到

  - 确认丢失

    B发送的对M1的确定丢失了，超出了超时计时器的时间，A并不知道自己是否发送成功，以此对M1进行重传。假设B又收到了重传的M1，这时应采取两个行动

    1. 丢弃这个重复的分组M1

    2. 向A发送确认

  - 确认迟到

    传输过程中没有出现差错，但B对M1的确认迟到了。A会收到重复的确认

    - 对重复确认的处理：收到后就丢弃，什么也不做
    - B也会收到重复的M1，同样要丢弃重复的M1，并重传确认分组


#### 连续ARQ协议

上述的可靠传输协议常称为自动重传请求（ARQ）

 发送方维持一个**发送窗口**，位于发送窗口内的分组可以连续发送出去，不需要等待对方的确，这样信道利用率就提高了。

连续ARQ协议规定，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。接收方不必对收到的分组逐个发送确认，而是在收到几个分组之后，对按序到达的最后一个分组发送确认。

Go-back-N：表示需要再退回来重传已发送过的N个分组。如果发送方发送了五个分组，而中间三个分组丢失了，这时接收方只能对前两个分组发出确认，发送方无法知道后面三个分组的下落，只好把后面三个分组都再重传一次

# TCP可靠传输的实现



### 超时重传时间的选择

采用一种**自适应算法**，记录一个报文段发出的时间，以及收到相应确认的时间，时间差就是往返时间RTT。每测量到一个新的RTT样本，就计算一次$RTT_s$，即加权平均往返时间，第一次测量的$RTT_s=RTT$

$新的RTT_s=(1-a)*(旧的RTT_s)+a*(新的RTT样本)$

a推荐设为1/8

超时重传时间应略大于$RTT_s$

$超时重传时间RTO=RTT_s+4*RTT_D$

$RTT_D$是RTT的偏差的平均加权值,第一次测量的$RTT_D=\frac{RTT}{2}$

$新的RTT_D=(1-B)*(旧的RTT_s)+B*|RTT_s-新的RTT样本|$

B推荐为1/4

### TCP的流量控制

接受主机通过控制接受窗口的大小进行流量控制，但当A收到零窗口后，B又有存储空间了，向A发送信息，告诉他新的接收窗口，但同时这个报文段丢失了，于是A一直等待B发送非零窗口的通知，B也一直在等待A发送数据，陷入死锁。为了解决这个问题， TCP为每一个连接设有一个**持续计时器**，只要TCP连接的一方收到零窗口通知，就启动持续计时器，只要时间到了，就发送一个零窗口**探测报文段**（仅携带1字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值，如果还是0，则重新设置持续计时器，如果不是，则死锁打破

### TCP的拥塞控制

在某段时间内，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况就叫作拥塞。

#### 避免方法

1. 慢开始
2. 拥塞避免
3. 快重传
4. 快恢复

- 慢开始和拥塞避免

  初始拥塞窗口cwnd设置为不超过2-4个SMSS的数值，若SMSS>2190字节则cwnd=2*SMSS字节，若>1095，则cwnd=3\*SMSS

  设置一个拥塞窗口，从小到大逐渐增大拥塞窗口数值。慢开始规定，在每收到一个对新的报文段的确认后，可以把拥塞窗口增加最多一个SMSS（发送方的最大报文段）数值。也就是min(N,SMSS)。

  N为原来未被确认的，但现在刚收到的确认报文段所确定的字节数

  还需要设置**慢开始门限ssthresh**，防止拥塞窗口cwnd增长过大引起网络堵塞。

  当cwnd>ssthresh时停止使用慢开始算法改用**拥塞避免算法**

  慢开始的cwnd是成倍增长，拥塞避免算法使拥塞窗口每次+1线性增长。

  假设ssthresh=16

  - 使用慢开始算法增长到ssthresh时改为拥塞避免算法cwnd每次+1
  - 网络发送堵塞时（cwnd=24），调整门限值为刚刚发生堵塞时cwnd的一半ssthresh=cwnd/2=12，使cwnd=1重新执行慢开始算法

- 快重传和快恢复

  个别报文段会在网络中意外丢失，但实际上网络并未发生拥塞，如果发送方迟迟收不到确认，就会产生超时误以为发生拥塞，导致重新执行慢开始，降低传输效率。采用**快重传算法可以让发送方尽早知道发送了个别报文段的丢失**。快重传算法要求接收方不要等到自己发送数据时才进行捎带确认，而是要**立即发送确认**，即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认。如M1M2都即使做出了确认，而M3丢失，接收方只收到了M4未收到M3，接收方必须立即发送对M2的重复确认，发送方接着发送给M5M6,接收方仍然对M2发送重复确认，这样接收方收到三个重复确认就知道并未出现网络拥塞，而只是接收方少收到一个报文段M3，因此立即进行重传M3（即**”快重传“**）

  继续上面的例子

  - cwnd达到12时，执行拥塞避免算法
  - cwnd=16时发生新情况：连续收到三个重复确认，发送方知道现在只是丢失了个别的报文段。于是不启动慢开始，而是执行**快恢复算法**，调整门限值，使ssthresh=cwnd/2=8，同时设置cwnd=ssthresh=8，并开始执行拥塞避免算法

  拥塞避免阶段cwnd线性增加，即加法增大（AI），出现超时或三个重复确认，门限值为当前cwnd的一半，即乘法减小（MD），合在一起就是所谓的AIMD算法

为了考虑流量控制，发送方窗口的上限值是min[rwnd,cwnd]

### 流量控制与拥塞控制的区别

| 对比维度               | **流量控制**                                                 | **拥塞控制**                                                 |
| ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **核心目标**           | 让发送方速率适配**接收方的处理能力**，避免接收方缓存被撑满   | 让发送方速率适配**网络的承载能力**，避免路由器队列溢出、数据丢失 |
| **控制对象**           | 发送方 ↔ 接收方（端到端的局部问题）                          | 发送方 ↔ 网络（全网的全局问题）                              |
| **关键参数**           | **接收窗口（rwnd）**：由接收方通过 `Window Size` 字段告知发送方，反映接收方剩余缓存空间 | **拥塞窗口（cwnd）**：由发送方根据网络状况动态计算，反映当前网络可承载的发送速率 |
| **发送窗口的决定因素** | 发送窗口 = 接收窗口（rwnd）                                  | 发送窗口 = **min (接收窗口 rwnd, 拥塞窗口 cwnd)**（最终发送速率由两者中较小的值决定） |
| **核心机制 / 算法**    | 滑动窗口机制、确认应答（ACK）                                | 慢开始、拥塞避免、快速重传、快速恢复                         |
| **触发条件**           | 接收方缓存不足（rwnd 减小）                                  | 网络拥塞（超时重传、3 个重复 ACK）                           |
| **调整策略**           | 接收方根据自身缓存动态调整 rwnd，发送方严格按照 rwnd 控制发送速率 | 发送方根据网络反馈动态调整 cwnd：1. 无拥塞 → cwnd 增长（指数 / 线性）2. 拥塞 → cwnd 降低 |
| **是否感知网络状态**   | 不感知，只关注接收方状态                                     | 必须感知，依赖网络丢包、延迟等反馈                           |

# TCP连接管理

TCP连接的建立采用客户服务器方式。主动发起连接建立的应用进程叫做**客户（client）**，被动等待连接建立的应用进程叫做**服务器（server）**

### 连接建立

首先创建传输控制块TCB

1. 客户端向服务器发送连接请求报文段，SYN=1，同时选择一个初始序列号seq=x，TCP规定SYN=1的报文段（SYN报文段）不能携带数据，但要消耗掉一个序号。这时客户进程进入SYN-SENT（同步已发送）状态

   `seq=x 表示：当前这个 TCP 报文段中，第一个字节在整个字节流中的位置是 x`

2. B收到连接请求报文段后，如同意建立连接，则向A发送确认。SYN=1，ACK=1，ack=x+1，同时也为自己选择一个初始序列号seq=y，这个报文段也不能携带数据，但同样要消耗一个序号，服务器进程进入SYN-RCVD（同步收到）状态

   `ack=x+1表示接收方已经正确收到了字节流中 k 及之前的所有字节，期望下一次接收的数据从字节位置 k+1 开始。`

3. 收到B的确认后，还要向B给出确认，确认报文段的ACK置为1，ack=y+1，seq=x+1，ACK报文段可以携带数据，但如果不携带数据则不消耗序号，在这种情况下，下一个数据报文段的序号仍是seq=x+1。这时TCP连接已经建立，A进入ESTABLITSHED（已建立连接）状态

   当B收到A的确认后也进入已建立连接状态

#### 为什么A最后还要发送一次确认？

主要是为了防止已失效的连接请求报文段突然又传送到了B，因为产生错误。

即A之前建立连接请求滞留了，很慢才到B，B同意请求时A已经不需要了，所以B一直在等A发数据，造成了B的资源浪费

### 连接释放

1. A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段的首部的终止控制位FIN置1，序号为u，它等于前面已传送过的数据的最后一个字节的序号+1，这时A进入FIN-WAIT-1（终止等待1）状态，FIN不携带数据，但也要消耗一个序号
2. B收到连接释放报文段后发出确认，确认号是ack=u+1，自己的序号是v，等于B前面已传送过的数据的最后一个字节的序号+1，然后B进入终止等待1状态，进入**半关闭**状态，即A已经没有数据发送了，不确定B是否还有数据，A收到来自B的确认后，进入终止等待2状态，等待B发出连接释放报文段
3. 若B没有数据要发送了，就发出连接释放报文段，FIN置为1，假设B的序号为w（半关闭状态可能发送了一些数据），重复上次已发送过的确认号ack=u+1，进入LAST-ACK（最后确认）状态，等待A的确认
4. A收到后发送确认，ACK置1，ack=w+1，seq=u+1，然后进入TIME-WAIT（时间等待）状态，必须经过2MSL才进入CLOSED状态，MSL为最长报文段寿命

撤销响应的传输控制块TCB后就结束了这次的TCP连接

#### 为什么要等2MSL（大约4分钟）

1. 保证A发送的最后一个ACK报文段能够到达B
2. 防止已失效的连接请求报文段出现在本连接中



















